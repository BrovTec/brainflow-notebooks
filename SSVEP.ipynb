{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time, strftime, gmtime\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mne import Epochs, find_events\n",
    "from mne.time_frequency import psd_welch\n",
    "from mne.decoding import Vectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n",
    "\n",
    "from pyriemann.estimation import Covariances, ERPCovariances, XdawnCovariances\n",
    "from pyriemann.spatialfilters import CSP\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import MDM\n",
    "\n",
    "from experiments import steadyStateEvokedPotentials\n",
    "from dataset import brainflowDataset\n",
    "from utils import plot_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SSVEP\n",
    "\n",
    "The steady-state visual evoked potential (SSVEP) is a repetitive evoked potential that is naturally produced when viewing stimuli flashing between a range of 6-75hz. Electrical activity at the same frequency as the visual stimulation can be detected in the occipital areas of the brain, likely due to the perceptual recreation of the stimulus in the primary visual cortex.\n",
    "\n",
    "The SSVEP is often used in BCI applications due to its ease of detection and the amount of information that a user can communicate due to the high potential frequency resolution of the SSVEP.\n",
    "\n",
    "In this notebook, we will use the Muse EEG headband with an extra occipital electrode to detect the SSVEP and evaluate it's use in SSVEP-based BCIs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<img src=\"https://eeg-notebooks.readthedocs.io/en/latest/_images/attaching_electrode.png\" style=\"height: 300px; float: right\"/>\n",
    "## Extra Electrode\n",
    "\n",
    "Although the SSVEP is detectable at the default temporal electrodes, it can be seen much more clearly directly over the occipital cortex.\n",
    "\n",
    "The Muse 2016 supports the addition of an extra electrode which can be connected through the devices microUSB charging port.\n",
    "\n",
    "- [Instructions on how to build an extra electrode for Muse](http://forum.choosemuse.com/t/step-by-step-tutorial-for-making-muse-auxilliary-channel-electrode/3172?u=tttz)\n",
    "- [Working with the extra electrode](https://eeg-notebooks.readthedocs.io/en/latest/using_an_extra_electrode_muse.html)\n",
    "\n",
    "For this experiment, the extra electrode should be placed at POz, right at the back of the skull. It can be secured in place with a bandana or a hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up the experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ssvep_exp = steadyStateEvokedPotentials()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize the EEG signal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# For tresting without connection\n",
    "ssvep_exp.initialize_eeg(board_type='synthetic')\n",
    "\n",
    "# For using the 8-channel Cyton board\n",
    "#ssvep_exp.initialize_eeg(board_type='cyton')\n",
    "\n",
    "# For using the 16-channel Cyton+Daisy combo\n",
    "#ssvep_exp.initialize_eeg(board_type='daisy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Beginning EEG Stream; Wait 5 seconds for signal to settle... \n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "subject_name = 'test_subject'\n",
    "duration = 10\n",
    "trial_num = 0\n",
    "ssvep_exp.run_trial(duration=duration,\n",
    "                    subject=subject_name,\n",
    "                    run=trial_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "runs = [0, 1, 2]\n",
    "dataset_ssvep = brainflowDataset(erp='ssvep', subject=subject_name)\n",
    "raw = dataset_ssvep.load_subject_to_raw(subject_name, runs, preprocess=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter the data and view PSD\n",
    "One way to analyze the SSVEP is to plot the power spectral density, or PSD. SSVEPs should appear as peaks in power for certain frequencies. We expect clear peaks in the spectral domain at the stimulation frequencies of 30 and 20 Hz.\n",
    "The justification for filtering 1-45 Hz is taken from... [**Find reference from Riemannian Geometric Classifier paper**]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw.filter(1, 45, method='iir')\n",
    "raw.plot_psd(fmin=1, fmax=45)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Epoching\n",
    "\n",
    "Next, we will chunk (epoch) the data into segments representing the data 100ms before to 800ms after each stimulus.\n",
    "\n",
    "*Note: we will not reject epochs here because the amplitude of the SSVEP at POz is so large it is difficult to separate from eye blinks*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "events = find_events(raw)\n",
    "event_id = {'30 Hz': 1, '20 Hz': 2}\n",
    "\n",
    "epochs = Epochs(raw, events=events, event_id=event_id, \n",
    "                tmin=-0.5, tmax=4, baseline=None, preload=True,\n",
    "                verbose=False, picks=[0, 1, 2, 3, 4])\n",
    "print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stimuli-Specific PSD\n",
    "\n",
    "Next, we can compare the PSD of epochs specifically during 20hz and 30hz stimulus presentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "psd1, freq1 = psd_welch(epochs['30 Hz'], n_fft=1028, n_per_seg=256 * 3)\n",
    "psd2, freq2 = psd_welch(epochs['20 Hz'], n_fft=1028, n_per_seg=256 * 3)\n",
    "psd1 = 10 * np.log10(psd1)\n",
    "psd2 = 10 * np.log10(psd2)\n",
    "\n",
    "psd1_mean = psd1.mean(0)\n",
    "psd1_std = psd1.mean(0)\n",
    "\n",
    "psd2_mean = psd2.mean(0)\n",
    "psd2_std = psd2.mean(0)\n",
    "\n",
    "axs[0].plot(freq1, psd1_mean[[0, 3], :].mean(0), color='b', label='30 Hz')\n",
    "axs[0].plot(freq2, psd2_mean[[0, 3], :].mean(0), color='r', label='20 Hz')\n",
    "\n",
    "axs[1].plot(freq1, psd1_mean[4, :], color='b', label='30 Hz')\n",
    "axs[1].plot(freq2, psd2_mean[4, :], color='r', label='20 Hz')\n",
    "\n",
    "axs[0].set_title('TP9 and TP10')\n",
    "axs[1].set_title('POz')\n",
    "axs[0].set_ylabel('Power Spectral Density (dB)')\n",
    "axs[1].set_ylabel('Power Spectral Density (dB)')\n",
    "axs[0].set_xlim((2, 50))\n",
    "axs[1].set_xlim((2, 50))\n",
    "axs[1].set_xlabel('Frequency (Hz)')\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With this visualization we can clearly see distinct peaks at 30hz and 20hz in the PSD, corresponding to the frequency of the visual stimulation. The peaks are much larger at the POz electrode, but still visible at TP9 and TP10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Spectrogram\n",
    "We can also look for SSVEPs in the spectrogram, which uses color to represent the power of frequencies in the EEG signal over time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mne.time_frequency import tfr_morlet\n",
    "\n",
    "frequencies = np.logspace(1, 1.75, 60)\n",
    "tfr, itc = tfr_morlet(epochs['30 Hz'], freqs=frequencies, \n",
    "                      n_cycles=15, return_itc=True)\n",
    "tfr.plot(picks=[4], baseline=(-0.5, -0.1), mode='logratio', \n",
    "         title='POz - 30 Hz stim');\n",
    "\n",
    "tfr, itc = tfr_morlet(epochs['20 Hz'], freqs=frequencies, \n",
    "                      n_cycles=15, return_itc=True)\n",
    "tfr.plot(picks=[4], baseline=(-0.5, -0.1), mode='logratio', \n",
    "         title='POz - 20 Hz stim');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once again we can see clear SSVEPs at 30hz and 20hz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decoding\n",
    "\n",
    "We can use a filter bank approach on the original 4 Muse electrodes (to see how the headband alone without external electrodes could be used to classify SSVEP):\n",
    "\n",
    "1. Apply bandpass filters around both stimulation frequencies\n",
    "2. Concatenate bandpass-filtered channels\n",
    "2. Extract epochs (from 1 to 3 s after stimulus onset, to avoid classifying the ERP)\n",
    "3. Apply common classification pipelines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bandpass filter the raw data\n",
    "muse_raw = raw.drop_channels(['POz'])\n",
    "raw_filt_30Hz = muse_raw.copy().filter(25, 35, method='iir')\n",
    "raw_filt_20Hz = muse_raw.copy().filter(15, 25, method='iir')\n",
    "raw_filt_30Hz.rename_channels(lambda x: x + '_30Hz')\n",
    "raw_filt_20Hz.rename_channels(lambda x: x + '_20Hz')\n",
    "\n",
    "# Concatenate with the bandpass filtered channels\n",
    "raw_all = raw_filt_30Hz.add_channels([raw_filt_20Hz], \n",
    "                                    force_update_info=True)\n",
    "\n",
    "# Extract epochs\n",
    "events = find_events(raw_all)\n",
    "event_id = {'30 Hz': 1, '20 Hz': 2}\n",
    "\n",
    "epochs_all = Epochs(raw_all, events=events, event_id=event_id, tmin=1, \n",
    "                     tmax=3, baseline=None, reject={'eeg': 100e-6}, \n",
    "                     preload=True, verbose=False,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs_all.pick_types(eeg=True)\n",
    "X = epochs_all.get_data() * 1e6\n",
    "times = epochs.times\n",
    "y = epochs_all.events[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decoding the N170\n",
    "\n",
    "Next, we will use 4 different machine learning pipelines to classify the SSVEP based on the data we collected. The \n",
    "\n",
    "- **CSP + RegLDA** :  Common Spatial Patterns + Regularized Linear Discriminat Analysis. This is a very common EEG analysis pipeline.\n",
    "- **Cov + TS** :  Covariance + Tangent space mapping. One of the most reliable Riemannian geometry-based pipelines.\n",
    "- **Cov + MDM**: Covariance + MDM. A very simple, yet effective (for low channel count), Riemannian geometry classifier.\n",
    "- **CSP + Cov + TS**: Common Spatial Patterns + Covariance + Tangent spacem mapping. Riemannian pipeline with the standard CSP procedure beforehand\n",
    "\n",
    "Evaluation is done through cross-validation, with area-under-the-curve (AUC) as metric (AUC is probably the best metric for binary and unbalanced classification problem)\n",
    "\n",
    "*Note: because we're doing machine learning here, the following cell may take a while to complete*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clfs = OrderedDict()\n",
    "\n",
    "clfs['CSP + RegLDA'] = make_pipeline(Covariances(), CSP(4), LDA(shrinkage='auto', solver='eigen'))\n",
    "clfs['Cov + TS'] = make_pipeline(Covariances(), TangentSpace(), LogisticRegression())\n",
    "clfs['Cov + MDM'] = make_pipeline(Covariances(), MDM())\n",
    "clfs['CSP + Cov + TS'] = make_pipeline(Covariances(), CSP(4, log=False), TangentSpace(), LogisticRegression())\n",
    "\n",
    "# define cross validation \n",
    "cv = StratifiedShuffleSplit(n_splits=20, test_size=0.25, \n",
    "                            random_state=42)\n",
    "\n",
    "# run cross validation for each pipeline\n",
    "auc = []\n",
    "methods = []\n",
    "for m in clfs:\n",
    "    print(m)\n",
    "    try:\n",
    "        res = cross_val_score(clfs[m], X, y==2, scoring='roc_auc', \n",
    "                              cv=cv, n_jobs=-1)\n",
    "        auc.extend(res)\n",
    "        methods.extend([m]*len(res))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "results = pd.DataFrame(data=auc, columns=['AUC'])\n",
    "results['Method'] = methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[8,4])\n",
    "sns.barplot(data=results, x='AUC', y='Method')\n",
    "plt.xlim(0.4, 1)\n",
    "sns.despine()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The different classifiers get some impressive accuracy on this dataset, all around .95 AUC. This is impressive considering this pipeline only included data from the temporal electrodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6: Share your Data!\n",
    "\n",
    "How did your experiment go? If you're excited by your results we'd love to see your data!\n",
    "\n",
    "Follow the instructions on our [Contributions](https://github.com/NeuroTechX/eeg-notebooks/blob/master/CONTRIBUTING.md) page to make a pull request with your data and we'll review it to be added to the EEG notebooks project."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}